{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Neda Jabbari;\n",
    "Sep 2019\n",
    "\n",
    "\n",
    "\n",
    "### Multiclass Logistic Regression and Genomics\n",
    "\n",
    "##### Scenario #1: \n",
    "A customer walks into a car dealership to buy a car. Given the customer's age and budget what are the chances that they will buy that specific BMW that the dealer showed them?  \n",
    "\n",
    "##### Scenario #2: \n",
    "A customer walks into a car dealership to buy a car. Given the customer's age and budget what is the likelihood of buying a particular model that the dealer showed them (with choices of Toyota, Chevrolet and BMW)? \n",
    "\n",
    "If you have ever wondered how you could use statistics to answer such questions, \"logistic regression\" is one answer. At times, we need to know the likelihood of a certain outcome of a dependent categorical variable (e.g. buying the particular BMW) given a set of features (customer's budget and age). As a binary regression, logistic regression estimates the relationship between independent variables and a certain output of a binary variable. Other times, we are interested in the likelihood of any of the multiple outcomes (e.g. buying any of the certain car models). In this case, a logistic regression is extended to several classes or events to figure out the likelihood of each. We refer to this as multiclass logistic regression. \n",
    "\n",
    "##### Objective:\n",
    "\n",
    "Based on my interest in genomics and certain years of experience working on Borrelia genomes, I decided to see if the size and GC content of bacterial chromosome assembly can help tease apart bacterial subgroups. Let me give a little background on the question: Chromosomes are made of DNA and DNA consists of 4 bases of G, C, T and A. A chromosome GC content is the percentage of G and C bases to the total bases in the chromosome. \n",
    "\n",
    "\n",
    "##### Data Source:\n",
    "I extracted the size and GC content of bacterial chromosome level assemblies from NCBI genome database. (https://www.ncbi.nlm.nih.gov/genome). I limited my data to bacteria with human host and one scaffold assembly. In addition, I only considered the three subgroups of Gammaproteobacteria, Firmicutes and Actinobacteria since the number of submissions in these subgroups were relatively comparable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('prokaryotes.csv')\n",
    "df['Organism Groups'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure out what Organism Groups have above 100 available submissions in dataset . \n",
    "summary = df.groupby('Organism Groups')[['Size(Mb)','GC%']].describe()\n",
    "bigenough = summary[summary['Size(Mb)']['count'] > 100]\n",
    "bigenough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep 'Gammaproteobacteria','Actinobacteria','Firmicutes' with >100 chromosome level assemblies.\n",
    "df['Organism Groups'] = [i.split(sep=';')[-1] for i in df['Organism Groups']]\n",
    "bacclasses = ['Gammaproteobacteria','Actinobacteria','Firmicutes']\n",
    "inbacclass = df['Organism Groups'].isin(bacclasses)\n",
    "df = df[inbacclass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep those with one scaffold in the assembly.\n",
    "df = df[df['Scaffolds']==1]\n",
    "df.groupby('Organism Groups').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Organism Groups'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the subgroups Firmicutes, Actinobacteria and Gammaproteobacteria with 0, 1, and 2 accordingly. \n",
    "bacecode = dict(zip(df['Organism Groups'].unique(),range(3)))\n",
    "df['Organism Groups'] = df['Organism Groups'].replace(bacecode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Organism Groups'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to get started for modeling. First, I prepare an X set as a dataframe with features \"Size(Mb)\" and \"GC%\" and a y series for Organism Groups and then split the data into train and test using a test size of 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Organism Groups']\n",
    "features = ['Size(Mb)','GC%']\n",
    "X = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into train and test \n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass logistic regression\n",
    "Here, I fit the model to train set and predict on test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression() #instantiate the model with the default parameters\n",
    "result = logreg.fit(X_train,y_train)   \n",
    "y_pred=logreg.predict(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### But how well did the algorithm perform?\n",
    "\n",
    "Let’s look at the coefficient of the features in my function. The coefficients represent log odds and are separately calculated for each independent variable in each class of the dependent variable.\n",
    "\n",
    "These log odds follow from the the “logistic function” thresholding used in the model https://en.wikipedia.org/wiki/Logistic_function.\n",
    "\n",
    "##### What do the classifier coefficients mean and how can I interpret them to evaluate the performance of my model?\n",
    "\n",
    "Each estimated coefficient is the expected change in the log odds of being in the relevant class for a unit increase in the predictor variable while the other variables are held constant. For example, the first coefficient of 0.032 (top left value in the above array) means that if we hold GC content constant, we will see 0.032% increase in the odds of getting classified as subgroup Firmicutes for a one-unit increase in the assembly size (exp(0.032) = 1.032). In other words, the odds for subgroup Firmicutes is 0.032% higher than the odds for other groups.\n",
    "The intercept is the coefficient of the reference category and shows the predicted outcome for the reference condition that is not present in the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.coef_)\n",
    "print(result.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### More on Model Evaluation: Confusion Matrix\n",
    "\n",
    "To further evaluate the model, I generated a confusion matrix using y test and y predicted set. Through the method “classification_report” of sklearn I calculated the following important metrics:\n",
    "* Precision: ratio of correct positives to total predicted positive (true positives to true positives and false positives)\n",
    "* Recall: ratio of correct positives to total actual positive (true positives to true positives and false negatives)\n",
    "* F1-score: a metric that combines precision and recall.\n",
    "\n",
    "The importance of each metric depends on what your model tries to best accomplish: If it is more important to avoid false positives, precision is the metric to optimize. Alternatively, if it is more important to avoid false negatives, recall is the metric that you want to optimize. And in general, the higher the f1-score, the better your model is. Below, you can see these metrics in each row for each of the subgroups Firmicutes, Actinobacteria and Gammaproteobacteria denoted as 0,1 and 2 in order.\n",
    "\n",
    "Here is more on sklearn’s confusion matrix : https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "#calculate precision, recall and f1\n",
    "metrics.classification_report(y_test, y_pred).split(sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I generated the same confusion matrix as a heatmap. It suggests a classification accuracy of 88%. This means that 88% of the times an assembly of a given size and GC content is truly predicted to belong to an outcome subgroup. Respectively, the ERR of 0.12 represents the ratio of misclassified positive and negative classes to all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create heatmap\n",
    "class_names=['Firmicutes','Actinobacteria','Gammaproteobacteria'] \n",
    "plt.figure(1, figsize=(9, 6))\n",
    "tick_marks = np.arange(len(class_names))\n",
    "sns.set(font_scale=1.6)\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix, \n",
    "                         index = ['Firmicutes','Actinobacteria','Gammaproteobacteria'] ,\n",
    "                         columns=['Firmicutes','Actinobacteria','Gammaproteobacteria']), \n",
    "                         cmap='Blues', annot=True,fmt='g', annot_kws={\"size\": 20})\n",
    "plt.title('Confusion matrix',fontsize=20)\n",
    "plt.ylabel('Actual', fontsize=14)\n",
    "plt.xlabel('Predicted',fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy (66+49+92)/len(y_test)\n",
    "metrics.accuracy_score(y_test, y_pred)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### More on Model Evaluation: Decision Boundary\n",
    "Another way to evaluate the performance of my model is to estimate decision boundaries that separate the classes. Given my classification problem with three distinct bacterial subgroups, my function trains three classifiers where each classifier draws a decision boundary for one class vs all other classes. For each class it selects a threshold value above which it assigns values into the class with the highest predicted probability. This plot shows decision boundaries for all three classes with different colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision boundary. Assign a color to each point in the mesh.\n",
    "X = np.array(X_test)  \n",
    "Y = np.array(y_test)\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - 1.5, X[:, 1].max() + 1.5\n",
    "#specify step size in the mesh\n",
    "h = .02  \n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "# make map prediction at every point on the grid\n",
    "Z = logreg.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.figure(1, figsize=(12, 8))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Dark2)\n",
    "\n",
    "labels = ['Firmicutes','Actinobacteria','Gammaproteobacteria']\n",
    "colors = [0,4,7]\n",
    "for i in range(3):\n",
    "    subset = Y == i\n",
    "    plt.scatter(X[subset, 0], X[subset, 1], edgecolors='k', s=150, \n",
    "                color =plt.cm.Dark2.colors[colors[i]] , label = labels[i])\n",
    "    \n",
    "plt.xlabel('Size(MB)', fontsize=14)\n",
    "plt.ylabel('GC%', fontsize=14)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "leg = plt.legend(loc = 'upper left',fontsize = 14, framealpha=0.01)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can also use the “predict_proba” method to get estimates for all classes at a given assembly size(MB) and GC content. For example, with an assembly size of 7 MB and GC content of 50% falling in the grey region, the bacterial subgroup is most probable Gammaproteobacteria since this subgroup has the highest probability for the given features as shown below. \n",
    "\n",
    "Here you can find an sklearn example of logistic regression 3 class classifier: https://scikit-learn.org/stable/auto_examples/linear_model/plot_iris_logistic.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.predict_proba([[7,50]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### More on Evaluation: ROC curves\n",
    "Another way to evaluate the output of our classifier is to look at ROC curves. ROC curve for each class is a plot of the class’s true positive rate (Y axis) against its false positive rate (X axis), a trade between sensitivity and specificity. The black line is represents a model that randomly guesses the class and any classifier with a curve above and farther away from the black line is better. The classifier that is closer to the ideal point of a true positive rate of one and a false positive rate of zero approaching the top left corner of the plot is better. This means a steeper ROC curve and also implies a larger area under the curve (AUC).\n",
    "In order to plot ROC curve for multi-class classification, we need to binarize the output variable using the one-vs-all classification strategy and draw one ROC curve per class. \n",
    "\n",
    "Sklearn has built in functions for ROC curves (https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one vs all classifier\n",
    "classifier = OneVsRestClassifier(LogisticRegression())\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)  \n",
    "\n",
    "# Compute ROC curves for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(3):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test.values == i, y_score[:,i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(1, figsize=(12, 8))\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(3), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color,\n",
    "             label=f\"ROC curve of class {i} is {round(roc_auc[i],2)}\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC for multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multiclass logistic regression model suggests that the GC content and assembly size can tease apart the three bacterial subgroups Gammaproteobacteria, Firmicutes and Actinobacteria with a good accuracy. So if more accurate information is missing on potential bacterial members of these subgroups, we could use these features to classify them into their subgroup with an acceptable accuracy. A nice application of logistic regression in bacterial genome studies!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
